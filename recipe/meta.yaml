{% set version = "3.2.1" %}
{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-lightgbm
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/lightgbm_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/lightgbm/lightgbm_{{ version }}.tar.gz
  sha256: 6d5e333f88d0bf6a23caea59438a1a3d63505b1d6ca5b6cf9c49bf314f6c6684

build:
  merge_build_host: true  # [win]
  number: 0
  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - {{ compiler('c') }}              # [not win]
    - {{ compiler('m2w64_c') }}        # [win]
    - {{ compiler('cxx') }}            # [not win]
    - {{ compiler('m2w64_cxx') }}      # [win]
    - {{ posix }}filesystem        # [win]
    - {{ posix }}sed               # [win]
    - {{ posix }}grep              # [win]
    - {{ posix }}autoconf
    - {{ posix }}automake          # [not win]
    - {{ posix }}automake-wrapper  # [win]
    - {{ posix }}pkg-config
    - {{ posix }}make
    - {{ posix }}coreutils         # [win]
    - {{ posix }}zip               # [win]
  host:
    - r-base
    - r-matrix >=1.1_0
    - r-r6 >=2.0
    - r-data.table >=1.9.6
    - r-jsonlite >=1.0
  run:
    - r-base
    - {{ native }}gcc-libs         # [win]
    - r-matrix >=1.1_0
    - r-r6 >=2.0
    - r-data.table >=1.9.6
    - r-jsonlite >=1.0

test:
  commands:
    - $R -e "library('lightgbm')"           # [not win]
    - "\"%R%\" -e \"library('lightgbm')\""  # [win]

about:
  home: https://github.com/Microsoft/LightGBM
  license: MIT
  summary: "Tree based algorithms can be improved by introducing boosting frameworks. 'LightGBM' is one such framework, based on Ke, Guolin et al. (2017) <https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision>. This package offers an R interface to work with it. It is designed to be distributed\
    \ and efficient with the following advantages: 1. Faster training speed and higher efficiency. 2. Lower memory usage. 3. Better accuracy. 4. Parallel learning supported. 5. Capable of handling large-scale data. In recognition of these advantages, 'LightGBM' has been widely-used in many winning solutions of machine learning\
    \ competitions. Comparison experiments on public datasets suggest that 'LightGBM' can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. In addition, parallel experiments suggest that in certain circumstances, 'LightGBM' can achieve a linear speed-up\
    \ in training time by using multiple machines."
  license_family: MIT
  license_file:
    - {{ environ["PREFIX"] }}/lib/R/share/licenses/MIT
    - LICENSE

extra:
  recipe-maintainers:
    - conda-forge/r
    - xhochy

# Package: lightgbm
# Type: Package
# Title: Light Gradient Boosting Machine
# Version: 3.1.0
# Date: 2020-11-15
# Authors@R: c( person("Guolin", "Ke", email = "guolin.ke@microsoft.com", role = c("aut", "cre")), person("Damien", "Soukhavong", email = "damien.soukhavong@skema.edu", role = c("aut")), person("James", "Lamb", email="jaylamb20@gmail.com", role = c("aut")), person("Qi", "Meng", role = c("aut")), person("Thomas", "Finley", role = c("aut")), person("Taifeng", "Wang", role = c("aut")), person("Wei", "Chen", role = c("aut")), person("Weidong", "Ma", role = c("aut")), person("Qiwei", "Ye", role = c("aut")), person("Tie-Yan", "Liu", role = c("aut")), person("Yachen", "Yan", role = c("ctb")), person("Microsoft Corporation", role = c("cph")), person("Dropbox, Inc.", role = c("cph")), person("Jay", "Loden", role = c("cph")), person("Dave", "Daeschler", role = c("cph")), person("Giampaolo", "Rodola", role = c("cph")), person("IBM Corporation", role = c("ctb")) )
# Description: Tree based algorithms can be improved by introducing boosting frameworks. 'LightGBM' is one such framework, based on Ke, Guolin et al. (2017) <https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision>. This package offers an R interface to work with it. It is designed to be distributed and efficient with the following advantages: 1. Faster training speed and higher efficiency. 2. Lower memory usage. 3. Better accuracy. 4. Parallel learning supported. 5. Capable of handling large-scale data. In recognition of these advantages, 'LightGBM' has been widely-used in many winning solutions of machine learning competitions. Comparison experiments on public datasets suggest that 'LightGBM' can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. In addition, parallel experiments suggest that in certain circumstances, 'LightGBM' can achieve a linear speed-up in training time by using multiple machines.
# Encoding: UTF-8
# License: MIT + file LICENSE
# URL: https://github.com/Microsoft/LightGBM
# BugReports: https://github.com/Microsoft/LightGBM/issues
# NeedsCompilation: yes
# Biarch: true
# Suggests: testthat
# Depends: R (>= 3.5), R6 (>= 2.0)
# Imports: data.table (>= 1.9.6), graphics, jsonlite (>= 1.0), Matrix (>= 1.1-0), methods, utils
# SystemRequirements: C++11
# RoxygenNote: 7.1.1
# Packaged: 2020-11-16 02:40:16 UTC; jlamb
# Author: Guolin Ke [aut, cre], Damien Soukhavong [aut], James Lamb [aut], Qi Meng [aut], Thomas Finley [aut], Taifeng Wang [aut], Wei Chen [aut], Weidong Ma [aut], Qiwei Ye [aut], Tie-Yan Liu [aut], Yachen Yan [ctb], Microsoft Corporation [cph], Dropbox, Inc. [cph], Jay Loden [cph], Dave Daeschler [cph], Giampaolo Rodola [cph], IBM Corporation [ctb]
# Maintainer: Guolin Ke <guolin.ke@microsoft.com>
# Repository: CRAN
# Date/Publication: 2020-11-18 23:20:11 UTC
